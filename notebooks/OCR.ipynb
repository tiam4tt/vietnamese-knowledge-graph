{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc7054a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import pytesseract\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb9d4df",
   "metadata": {},
   "source": [
    "# Function declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a02f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_png(pdf_path, output_folder, dpi=400):\n",
    "    # Open the PDF file\n",
    "    pdf_document = pymupdf.open(pdf_path)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    for page_number in tqdm(range(len(pdf_document)), desc=\"Converting PDF to PNG...\"):\n",
    "        # Load the page\n",
    "        page = pdf_document.load_page(page_number)\n",
    "        \n",
    "        # Render page to an image (pixmap)\n",
    "        pix = page.get_pixmap(dpi=dpi)\n",
    "        \n",
    "        # Define output image path\n",
    "        output_image_path = f\"{output_folder}/page_{page_number + 1}.png\"\n",
    "        \n",
    "        # Save the image\n",
    "        pix.save(output_image_path)\n",
    "        \n",
    "def pdf_to_text(pdf_path, output_folder, sample_page=None):\n",
    "    pdf_document = pymupdf.open(pdf_path)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    if sample_page is not None:\n",
    "        pages_to_process = [sample_page]\n",
    "    else:\n",
    "        pages_to_process = range(len(pdf_document))\n",
    "    \n",
    "    texts = {}\n",
    "    for page_number in pages_to_process:\n",
    "        page = pdf_document.load_page(page_number)\n",
    "        text = page.get_text()\n",
    "        texts[page_number] = text\n",
    "    \n",
    "    return texts\n",
    "\n",
    "def crop_header_footer(image_array: np.ndarray, threshold: int = 127):\n",
    "    \"\"\"\n",
    "    Crop header and footer from a grayscale image based on a pixel intensity threshold.\n",
    "\n",
    "    Args:\n",
    "        image_array (numpy.ndarray): Input image as a 2D array.\n",
    "        threshold (int): Pixel intensity threshold to identify content.\n",
    "    Returns:\n",
    "        numpy.ndarray: Cropped image array.\n",
    "    \"\"\"\n",
    "    height, _ = image_array.shape\n",
    "    row_text_counts = np.sum(image_array < threshold, axis=1)\n",
    "    has_text_signal = row_text_counts > 0\n",
    "    \n",
    "    # top crop (header)\n",
    "    top_crop_row = 0\n",
    "    reach_header = False\n",
    "    for i in range(height // 2):\n",
    "        if has_text_signal[i]:\n",
    "            reach_header = True\n",
    "        if reach_header and not has_text_signal[i]:\n",
    "            top_crop_row = i\n",
    "            break\n",
    "    \n",
    "    # bottom crop (footer)\n",
    "    bottom_crop_row = height\n",
    "    reach_footer = False\n",
    "    for i in range(height - 1, height // 2, -1):\n",
    "        if has_text_signal[i]:\n",
    "            reach_footer = True\n",
    "        if reach_footer and not has_text_signal[i]:\n",
    "            bottom_crop_row = i\n",
    "            break\n",
    "    \n",
    "    cropped_image = image_array[top_crop_row:bottom_crop_row, :]\n",
    "    return cropped_image\n",
    "    \n",
    "def convert_to_binary(image_array:np.ndarray, threshold:int = 90):\n",
    "    \"\"\"\n",
    "    Apply a black threshold to a grayscale image.\n",
    "\n",
    "    Args:\n",
    "        image_array (numpy.ndarray): Input image as a 2D array.\n",
    "        threshold (int): Threshold value to consider a pixel as black.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Binary image after applying the threshold.\n",
    "    \"\"\"\n",
    "    binary_image = np.where(image_array < threshold, 0, 255).astype(np.uint8)\n",
    "    return binary_image\n",
    "\n",
    "def apply_pooling(image, pool_size, stride, padding=0, min_pooling=True):\n",
    "    \"\"\"\n",
    "    Apply pooling (min or max) to an image efficiently using NumPy.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image as a 2D array.\n",
    "        pool_size (int): Size of the pooling window (n x n).\n",
    "        stride (int): Stride of the pooling window.\n",
    "        padding (int): Amount of zero padding to add to the image (default is 0).\n",
    "        min_pooling (bool): If True, apply min pooling; otherwise, apply max pooling.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Pooled image.\n",
    "    \"\"\"\n",
    "    # Add zero padding to the image\n",
    "    if padding > 0:\n",
    "        image = np.pad(image, pad_width=padding, mode='constant', constant_values=0)\n",
    "    \n",
    "    # Get dimensions of the input image\n",
    "    h, w = image.shape\n",
    "    \n",
    "    # Calculate dimensions of the output image\n",
    "    out_h = (h - pool_size) // stride + 1\n",
    "    out_w = (w - pool_size) // stride + 1\n",
    "    \n",
    "    # Create a sliding window view of the image\n",
    "    shape = (out_h, out_w, pool_size, pool_size)\n",
    "    strides = (stride * image.strides[0], stride * image.strides[1], image.strides[0], image.strides[1])\n",
    "    windows = np.lib.stride_tricks.as_strided(image, shape=shape, strides=strides)\n",
    "    \n",
    "    # Apply pooling operation\n",
    "    pooled_image = windows.min(axis=(2, 3)) if min_pooling else windows.max(axis=(2, 3))\n",
    "    \n",
    "    return pooled_image\n",
    "\n",
    "def poolling_and_ocr_image(image_array:np.ndarray, lang:str = 'vie', config:str = '--psm 3', pool_size:int = 2, stride:int = 1, min_pooling:bool=True):\n",
    "    \"\"\"\n",
    "    Apply pooling to an image and then perform OCR using Tesseract.\n",
    "\n",
    "    Args:\n",
    "        image_array (numpy.ndarray): Input image as a 2D array.\n",
    "        lang (str): Language for Tesseract OCR.\n",
    "        config (str): Configuration options for Tesseract OCR.\n",
    "        black_threshold (int): Threshold to consider a pixel as black.\n",
    "        pool_size (int): Size of the pooling window (n x n).\n",
    "        stride (int): Stride of the pooling window.\n",
    "        min_pooling (bool): If True, apply min pooling; otherwise, apply max pooling.\n",
    "    Returns:\n",
    "        str: Extracted text from the image.\n",
    "    \"\"\"\n",
    "    pooled_image = apply_pooling(image_array, pool_size, stride, padding=0, min_pooling=min_pooling)\n",
    "    image_obj = Image.fromarray(pooled_image)\n",
    "    \n",
    "    text = pytesseract.image_to_string(image_obj, lang=lang, config=config)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def divide_image(image_array:np.ndarray):\n",
    "    # document was displayed in 2 column style, find the gap and divide the image\n",
    "    _, width = image_array.shape\n",
    "    col_sum = np.sum(image_array < 127, axis=0)\n",
    "    gap_start, gap_end = None, None\n",
    "    in_gap = False\n",
    "    # the middle 20% area is more likely to contain the gap\n",
    "    start_col = width // 2 - width // 10\n",
    "    end_col = width // 2 + width // 10\n",
    "    for col in range(start_col, end_col):\n",
    "        if col_sum[col] == 0 and not in_gap:\n",
    "            gap_start = col\n",
    "            in_gap = True\n",
    "        elif col_sum[col] > 0 and in_gap:\n",
    "            gap_end = col\n",
    "            break\n",
    "    if gap_start is not None and gap_end is not None:\n",
    "        left_image = image_array[:, :gap_start]\n",
    "        right_image = image_array[:, gap_end:]\n",
    "        return left_image, right_image\n",
    "    else:\n",
    "        return image_array, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd494d0",
   "metadata": {},
   "source": [
    "# PDF to PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90f007a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_to_png(input_pdf, png_output_folder, dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf75437c",
   "metadata": {},
   "source": [
    "# Crop Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba6b8fa",
   "metadata": {},
   "source": [
    "# OCR\n",
    "\n",
    "Range: page **6 - 251**\n",
    "\n",
    "### Parameters\n",
    "- **Black Threshold:** 90\n",
    "- **Pool size:** 2\n",
    "- **Stride:** 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d20c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_threshold = 90\n",
    "pool_size = 2\n",
    "stride = 1\n",
    "min_pooling = True\n",
    "\n",
    "page_range = list(range(6, 252)) # 6 - 252\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe5c3b9",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba09564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting text from images...: 100%|██████████| 246/246 [16:28<00:00,  4.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# path declarations\n",
    "input_pdf = \"../data/raw/Duoc-Dien-Viet-Nam-V-tap-2.pdf\"\n",
    "png_output_folder = \"../data/raw/pdf_images\"\n",
    "processed_output_csv = \"../data/processed/ocr_output.csv\"\n",
    "\n",
    "for page_num in tqdm(page_range, desc=\"Extracting text from images...\"):\n",
    "    image_path = os.path.join(png_output_folder, f\"page_{page_num}.png\")\n",
    "    image_array = np.array(Image.open(image_path).convert('L'))\n",
    "    \n",
    "    image_array = convert_to_binary(image_array, threshold=black_threshold)\n",
    "    cropped_image = crop_header_footer(image_array, threshold=127)\n",
    "    \n",
    "    # save cropped image for inspection\n",
    "    # cropped_image_obj = Image.fromarray(cropped_image)\n",
    "    # cropped_image_obj.save(os.path.join(\"test_data\", f\"page_{page_num}_cropped.png\"))\n",
    "\n",
    "    text = poolling_and_ocr_image(cropped_image, lang='vie', config='--psm 3', pool_size=pool_size, stride=stride, min_pooling=min_pooling)\n",
    "    \n",
    "    results.append({\n",
    "        \"page_id\": page_num,\n",
    "        \"text\": text.strip()\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbf5fa4",
   "metadata": {},
   "source": [
    "### Process the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9de5371",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.to_csv(processed_output_csv, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6056cc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>QUI ĐỊNH CHUNG\\n\\n1]. Tên chính của các chuyên...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Mát: 10°C đến 20 °C.\\n\\nNhiệt độ phòng: 20 °C ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1]7. Trong chuyên luận kháng sinh, hl mục định...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>27. Hỗn hợp của các chất lỏng được ghi theo ký...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>39. Dược liệu dùng. sàn xuất thuốc thành phẩm ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_id                                               text\n",
       "0        6  QUI ĐỊNH CHUNG\\n\\n1]. Tên chính của các chuyên...\n",
       "1        7  Mát: 10°C đến 20 °C.\\n\\nNhiệt độ phòng: 20 °C ...\n",
       "2        8  1]7. Trong chuyên luận kháng sinh, hl mục định...\n",
       "3        9  27. Hỗn hợp của các chất lỏng được ghi theo ký...\n",
       "4       10  39. Dược liệu dùng. sàn xuất thuốc thành phẩm ..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/ocr_output.csv\", encoding='utf-8')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b40d2161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the text into a single txt file\n",
    "all_text = \" \".join(df['text'].tolist())\n",
    "with open(\"../data/raw/all_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(all_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle_ocr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
