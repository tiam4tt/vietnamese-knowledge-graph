{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4c800e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "allowed_nodes = [\n",
    "    \"DRUG\",            # Thuốc\n",
    "    \"DISEASE\",         # Bệnh\n",
    "    \"CHEMICAL\",        # Hóa chất/Thành phần\n",
    "    \"ORGANISM\",        # Vi sinh vật\n",
    "    \"TEST_METHOD\",      # Phương pháp thử\n",
    "    \"STANDARD\",        # Tiêu chuẩn\n",
    "    \"STORAGE_CONDITION\",# Bảo quản\n",
    "    \"PRODUCTION_METHOD\"       # Phương pháp sản xuất\n",
    "]\n",
    "\n",
    "allowed_relationships = [\n",
    "    \"TREATS\",          # Drug -> Disease\n",
    "    \"CONTAINS\",        # Drug -> Chemical\n",
    "    \"TARGETS\",         # Drug -> Organism\n",
    "    \"TESTED_BY\",       # Drug -> TestMethod\n",
    "    \"HAS_STANDARD\",    # Drug -> Standard\n",
    "    \"STORED_AT\",       # Drug -> Storage\n",
    "    \"PRODUCED_BY\",     # Drug -> Production\n",
    "    \"REQUIRES\"         # TestMethod -> Chemical\n",
    "]\n",
    "\n",
    "result_csv = \"../models/test_predictions.csv\"\n",
    "og_csv = \"../data/processed/ViKG-NLQ-2-Cypher-data-cleaned.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d0823a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Dict, Set\n",
    "\n",
    "def fix_query(TARGET_NODES, TARGET_RELS):\n",
    "    fuzzy_map = {}\n",
    "    for item in TARGET_NODES + TARGET_RELS:\n",
    "        key = item.replace(\"_\",\"\").upper() # TEST_METHOD -> TESTMETHOD\n",
    "        fuzzy_map[key] = item # handles labels with no underscores\n",
    "\n",
    "    def clean_text(text):\n",
    "        def replacer_func(match):\n",
    "            original_match = match.group(1)\n",
    "            lookup_key = original_match.replace(\"_\",\"\").upper()\n",
    "\n",
    "            if lookup_key in fuzzy_map:\n",
    "                return \":\" + fuzzy_map[lookup_key]\n",
    "            return match.group(0)\n",
    "\n",
    "        return re.sub(r':([a-zA-Z_]+)', replacer_func, text)\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "def normalize_cypher_query(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize a Cypher query by replacing variable names with standardized placeholders.\n",
    "    This allows comparing queries that are semantically identical but use different variable names.\n",
    "    \n",
    "    Args:\n",
    "        query: The Cypher query string to normalize\n",
    "        \n",
    "    Returns:\n",
    "        Normalized query with standardized variable names (var1, var2, etc.)\n",
    "    \"\"\"\n",
    "    if not query or not isinstance(query, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # First, protect string literals by temporarily replacing them\n",
    "    string_pattern = r'\"[^\"]*\"|\\'[^\\']*\\''\n",
    "    strings = []\n",
    "    \n",
    "    def save_string(match):\n",
    "        strings.append(match.group(0))\n",
    "        return f\"__STRING_{len(strings)-1}__\"\n",
    "    \n",
    "    # Temporarily replace strings with placeholders\n",
    "    query_no_strings = re.sub(string_pattern, save_string, query)\n",
    "    \n",
    "    # Extract all variable names from node and relationship patterns\n",
    "    variables = []\n",
    "    \n",
    "    # Match node patterns: (var:Label) or (var)\n",
    "    node_pattern = r'\\((\\w+)(?::\\w+(?:\\|\\w+)*)?\\)'\n",
    "    for match in re.finditer(node_pattern, query_no_strings):\n",
    "        var = match.group(1)\n",
    "        if var and not var.isupper() and not var.startswith('__STRING_'):\n",
    "            if var not in variables:\n",
    "                variables.append(var)\n",
    "    \n",
    "    # Match relationship patterns: -[var:REL]- or -[var]-\n",
    "    rel_pattern = r'-\\[(\\w+)(?::\\w+)?\\]-'\n",
    "    for match in re.finditer(rel_pattern, query_no_strings):\n",
    "        var = match.group(1)\n",
    "        if var and not var.isupper():\n",
    "            if var not in variables:\n",
    "                variables.append(var)\n",
    "    \n",
    "    # Create mapping from original variables to normalized ones\n",
    "    var_mapping = {var: f\"var{i+1}\" for i, var in enumerate(variables)}\n",
    "    \n",
    "    # Replace variables in the query (excluding strings)\n",
    "    normalized = query_no_strings\n",
    "    \n",
    "    # Sort by length (longest first) to avoid partial replacements\n",
    "    for original_var in sorted(var_mapping.keys(), key=len, reverse=True):\n",
    "        normalized_var = var_mapping[original_var]\n",
    "        # Use word boundaries to ensure we replace complete variable names\n",
    "        pattern = r'\\b' + re.escape(original_var) + r'\\b'\n",
    "        normalized = re.sub(pattern, normalized_var, normalized)\n",
    "    \n",
    "    # Restore string literals\n",
    "    for i, string in enumerate(strings):\n",
    "        normalized = normalized.replace(f\"__STRING_{i}__\", string)\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "\n",
    "def soft_exact_match(prediction: str, ground_truth: str) -> bool:\n",
    "    \"\"\"\n",
    "    Compare two Cypher queries with \"soft\" exact matching.\n",
    "    Returns True if queries are identical after normalizing variable names.\n",
    "    \n",
    "    Args:\n",
    "        prediction: The predicted Cypher query\n",
    "        ground_truth: The ground truth Cypher query\n",
    "        \n",
    "    Returns:\n",
    "        True if queries match after normalization, False otherwise\n",
    "    \"\"\"\n",
    "    norm_pred = normalize_cypher_query(prediction)\n",
    "    norm_truth = normalize_cypher_query(ground_truth)\n",
    "    \n",
    "    return norm_pred == norm_truth\n",
    "\n",
    "def compare_relationship_type(pred, gt):\n",
    "    pattern = re.compile(r'\\[.+:([A-Z_]+)\\]')\n",
    "    pred_entities = re.findall(pattern, pred)\n",
    "    gt_entities = re.findall(pattern, gt)\n",
    "    \n",
    "    return set(pred_entities) == set(gt_entities)\n",
    "    \n",
    "def compare_entity_type(pred, gt):\n",
    "    pattern = re.compile(r'\\(.+:([A-Z_]+)\\)')\n",
    "    pred_entities = re.findall(pattern, pred)\n",
    "    gt_entities = re.findall(pattern, gt)\n",
    "    \n",
    "    return set(pred_entities) == set(gt_entities)\n",
    "\n",
    "def compare_entity_name(pred, gt):\n",
    "    pattern = re.compile(r'\\\"(\\w+)\\\"')\n",
    "    pred_entities = re.findall(pattern, pred)\n",
    "    gt_entities = re.findall(pattern, gt)\n",
    "    \n",
    "    return set(pred_entities) == set(gt_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9942a725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541 entries, 0 to 540\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   prediction    541 non-null    object\n",
      " 1   ground_truth  541 non-null    object\n",
      " 2   match         541 non-null    bool  \n",
      "dtypes: bool(1), object(2)\n",
      "memory usage: 9.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(result_csv, encoding=\"utf-8\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f58b3f",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62036655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Exact Match Accuracy: 357/541 - 65.99%\n",
      "Soft Exact Match Accuracy: 395/541 - 73.01%\n",
      "Index: 444\n",
      "Prediction: MATCH (d:D)-[:TESTEDBY](t:TESTMETHOD) WHERE toLower(d.id) CONTAINS \"vắc xin thành phẩm\" RETURN t.id\n",
      "Ground Truth: MATCH (d:D)-[:TESTEDBY](t:TESTMETHOD) WHERE toLower(d.id) CONTAINS \"vắc xin thành phẩm\" AND (toLower(t.id) CONTAINS \"chất bảo quản\" OR toLower(t.id) CONTAINS \"ph\" OR toLower(t.id) CONTAINS \"nhận dạng\") RETURN t.id\n",
      "--------------------------------------------------\n",
      "Index: 346\n",
      "Prediction: MATCH (t:TESTMETHOD)-[:HASSTANDARD](s:STANDARD) WHERE toLower(t.id) CONTAINS \"phụ lục 9.6\" RETURN s.id\n",
      "Ground Truth: MATCH (tm:TESTMETHOD)-[:REQUIRES](s:STANDARD) WHERE toLower(tm.id) CONTAINS \"phụ lục 9.6\" AND toLower(s.id) CONTAINS \"h\" RETURN s.id\n",
      "--------------------------------------------------\n",
      "Index: 268\n",
      "Prediction: MATCH (t:TESTMETHOD)-[:HASSTANDARD](s:STANDARD) WHERE toLower(t.id) CONTAINS \"chiết nóng\" RETURN s.id\n",
      "Ground Truth: MATCH (s:STANDARD)-[:REQUIRES](tm:TESTMETHOD) WHERE toLower(tm.id) CONTAINS \"phương pháp chiết nóng\" RETURN s.id\n",
      "--------------------------------------------------\n",
      "Index: 10\n",
      "Prediction: MATCH (t:TESTMETHOD)-[:REQUIRES](c:CHEMICAL) WHERE toLower(t.id) CONTAINS \"sắc ký lỏng\" AND toLower(c.id) CONTAINS \"pha tĩnh\" RETURN c.id\n",
      "Ground Truth: MATCH (t:TESTMETHOD)-[:REQUIRES](c:CHEMICAL) WHERE toLower(t.id) CONTAINS \"sắc ký lỏng\" AND toLower(c.id) CONTAINS \"c18\" RETURN c.id\n",
      "--------------------------------------------------\n",
      "Index: 226\n",
      "Prediction: MATCH (d:D)-[:HASSTANDARD](s:STANDARD) WHERE toLower(d.id) CONTAINS \"vắc xin thương hàn vi polysaccharid\" AND toLower(s.id) CONTAINS \"an toàn không đặc hiệu\" RETURN s.id\n",
      "Ground Truth: MATCH (d:D)-[:HASSTANDARD](s:STANDARD) WHERE toLower(d.id) CONTAINS \"thương hàn vi polysaccharid\" AND toLower(s.id) CONTAINS \"an toàn không đặc hiệu\" RETURN s.id\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df['soft_exact_match'] = df.apply(lambda row: soft_exact_match(row['prediction'], row['ground_truth']), axis=1)\n",
    "\n",
    "soft_accuracy = df['soft_exact_match'].sum() / len(df)\n",
    "print(f\"Hard Exact Match Accuracy: {df['match'].sum()}/{len(df)} - {(df['match']).sum() / len(df) * 100:.2f}%\")\n",
    "print(f\"Soft Exact Match Accuracy: {df['soft_exact_match'].sum()}/{len(df)} - {soft_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Wrong predictions analysis\n",
    "wrong_predictions = df[df['soft_exact_match'] == False]\n",
    "samples = wrong_predictions.sample(5)\n",
    "\n",
    "for idx, row in samples.iterrows():\n",
    "    print(f\"Index: {idx}\")\n",
    "    print(f\"Prediction: {row['prediction']}\")\n",
    "    print(f\"Ground Truth: {row['ground_truth']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a948ea7",
   "metadata": {},
   "source": [
    "## Entity Type Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41780486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Type Match Accuracy: 529/541 (98%)\n",
      "Entity Type Mismatch Count: 12 (2%)\n",
      "\n",
      "Index: 455\n",
      "Prediction: MATCH (c:CHEMICAL)-[:PRODUCEDBY](o:ORGANISM) WHERE toLower(c.id) CONTAINS \"kháng nguyên bề mặt (hbsag)\" RETURN o.id\n",
      "Ground Truth: MATCH (o:ORGANISM)<-[:PRODUCEDBY]-(c:CHEMICAL) WHERE toLower(c.id) CONTAINS \"hbsag\" RETURN o.id\n",
      "--------------------------------------------------\n",
      "Index: 432\n",
      "Prediction: MATCH (t:TESTMETHOD)-[:HASSTANDARD](s:STANDARD) WHERE toLower(t.id) CONTAINS \"định lượng\" RETURN s.id\n",
      "Ground Truth: MATCH (s:STANDARD)-[:TESTEDBY](tm:TESTMETHOD) WHERE toLower(tm.id) CONTAINS \"định lượng\" RETURN s.id\n",
      "--------------------------------------------------\n",
      "Index: 47\n",
      "Prediction: MATCH (d:D)-[:PRODUCEDBY](o:ORGANISM) WHERE toLower(d.id) CONTAINS \"cỏ mần\" RETURN o.id\n",
      "Ground Truth: MATCH (d:D)-[:PRODUCEDBY](p:PRODUCTIONMETHOD) WHERE toLower(d.id) CONTAINS \"cỏ mần\" RETURN p.id\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df['entity_type_match'] = df.apply(lambda row: compare_entity_type(row['prediction'], row['ground_truth']), axis=1)\n",
    "entity_type_accuracy = df['entity_type_match'].value_counts().to_dict()\n",
    "\n",
    "print(f\"Entity Type Match Accuracy: {entity_type_accuracy[True]}/{len(df)} ({entity_type_accuracy[True] / len(df) * 100:.0f}%)\")\n",
    "print(f\"Entity Type Mismatch Count: {entity_type_accuracy.get(False, 0)} ({entity_type_accuracy.get(False, 0) / len(df) * 100:.0f}%)\")\n",
    "print()\n",
    "# sample\n",
    "wrong_entity_type = df[df['entity_type_match'] == False].sample(3, random_state=42)\n",
    "for idx, row in wrong_entity_type.iterrows():\n",
    "    print(f\"Index: {idx}\")\n",
    "    print(f\"Prediction: {row['prediction']}\")\n",
    "    print(f\"Ground Truth: {row['ground_truth']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d47019e",
   "metadata": {},
   "source": [
    "## Relation Type Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f000812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship Type Match Accuracy: 526/541 (97%)\n",
      "Relationship Type Mismatch Count: 15 (3%)\n",
      "\n",
      "Index: 320\n",
      "Prediction: MATCH (t:TESTMETHOD)-[:HASSTANDARD](s:STANDARD) WHERE toLower(t.id) CONTAINS \"sắc ký lỏng\" RETURN s.id\n",
      "Ground Truth: MATCH (m:TESTMETHOD)<-[:TESTEDBY]-(d:D)-[:HASSTANDARD](s:STANDARD) WHERE toLower(m.id) CONTAINS \"sắc ký lỏng\" RETURN s.id\n",
      "--------------------------------------------------\n",
      "Index: 360\n",
      "Prediction: MATCH (d:D)-[:HASSTANDARD](s:STANDARD)-[:TESTEDBY](tm:TESTMETHOD) WHERE toLower(d.id) CONTAINS \"tỷ lệ vụn nát\" RETURN tm.id\n",
      "Ground Truth: MATCH (s:STANDARD)-[:TESTEDBY](tm:TESTMETHOD) WHERE toLower(s.id) CONTAINS \"tỷ lệ vụn nát\" RETURN tm.id\n",
      "--------------------------------------------------\n",
      "Index: 105\n",
      "Prediction: MATCH (tm:TESTMETHOD)<-[:TESTEDBY]-(d:D)-[:HASSTANDARD](s:STANDARD) WHERE toLower(tm.id) CONTAINS \"phụ lục 9.8\" RETURN s.id\n",
      "Ground Truth: MATCH (tm:TESTMETHOD)<-[:TESTEDBY]-(s:STANDARD) WHERE toLower(tm.id) CONTAINS \"phụ lục 9.8\" RETURN s.id\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df['rel_type_match'] = df.apply(lambda row: compare_relationship_type(row['prediction'], row['ground_truth']), axis=1)\n",
    "rel_type_accuracy = df['rel_type_match'].value_counts().to_dict()\n",
    "\n",
    "print(f\"Relationship Type Match Accuracy: {rel_type_accuracy[True]}/{len(df)} ({rel_type_accuracy[True] / len(df) * 100:.0f}%)\")\n",
    "print(f\"Relationship Type Mismatch Count: {rel_type_accuracy.get(False, 0)} ({rel_type_accuracy.get(False, 0) / len(df) * 100:.0f}%)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# mismatch samples\n",
    "wrong_rel_type = df[df['rel_type_match'] == False].sample(3, random_state=42)\n",
    "for idx, row in wrong_rel_type.iterrows():\n",
    "    print(f\"Index: {idx}\")\n",
    "    print(f\"Prediction: {row['prediction']}\")\n",
    "    print(f\"Ground Truth: {row['ground_truth']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755daec0",
   "metadata": {},
   "source": [
    "## Entity Name identification error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44cd9dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Name Match Accuracy: 511/541 (94%)\n",
      "Entity Name Mismatch Count: 30 (6%)\n",
      "Index: 473\n",
      "Prediction: MATCH (t:TESTMETHOD)-[:REQUIRES](c:CHEMICAL) WHERE toLower(t.id) CONTAINS \"sắc ký lớp mỏng (dung môi 2)\" RETURN c.id\n",
      "Ground Truth: MATCH (tm:TESTMETHOD)-[:REQUIRES](d:D) WHERE toLower(tm.id) CONTAINS \"sắc ký lớp mỏng\" AND toLower(tm.id) CONTAINS \"toluen\" RETURN d.id\n",
      "--------------------------------------------------\n",
      "Index: 346\n",
      "Prediction: MATCH (t:TESTMETHOD)-[:HASSTANDARD](s:STANDARD) WHERE toLower(t.id) CONTAINS \"phụ lục 9.6\" RETURN s.id\n",
      "Ground Truth: MATCH (tm:TESTMETHOD)-[:REQUIRES](s:STANDARD) WHERE toLower(tm.id) CONTAINS \"phụ lục 9.6\" AND toLower(s.id) CONTAINS \"h\" RETURN s.id\n",
      "--------------------------------------------------\n",
      "Index: 439\n",
      "Prediction: MATCH (d:D)-[:TESTEDBY](tm:TESTMETHOD) WHERE toLower(d.id) CONTAINS \"hemagglutinin\" RETURN tm.id\n",
      "Ground Truth: MATCH (d:D)-[:TESTEDBY](tm:TESTMETHOD) WHERE toLower(tm.id) CONTAINS \"khuếch tán miễn dịch đơn\" RETURN tm.id\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## Entity Name identification error\n",
    "df['entity_name_match'] = df.apply(lambda row: compare_entity_name(row['prediction'], row['ground_truth']), axis=1)\n",
    "entity_name_accuracy = df['entity_name_match'].value_counts().to_dict()\n",
    "\n",
    "print(f\"Entity Name Match Accuracy: {entity_name_accuracy[True]}/{len(df)} ({entity_name_accuracy[True] / len(df) * 100:.0f}%)\")\n",
    "print(f\"Entity Name Mismatch Count: {entity_name_accuracy.get(False, 0)} ({entity_name_accuracy.get(False, 0) / len(df) * 100:.0f}%)\")\n",
    "\n",
    "# sample\n",
    "wrong_entity_name = df[df['entity_name_match'] == False].sample(3, random_state=42)\n",
    "for idx, row in wrong_entity_name.iterrows():\n",
    "    print(f\"Index: {idx}\")\n",
    "    print(f\"Prediction: {row['prediction']}\")\n",
    "    print(f\"Ground Truth: {row['ground_truth']}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ViKG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
